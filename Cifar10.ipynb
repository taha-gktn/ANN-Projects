{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOOOy2N+xhqQ0VFJnHAETek",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taha-gktn/ANN-Projects/blob/main/Cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aQ1CqV2fTb5f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, BatchNormalization, Conv2D, Flatten,MaxPooling2D, Activation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# data\n",
        "from tensorflow.keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhcrGQQ9Td2k",
        "outputId": "5628b214-cda6-418e-f1c8-6d6facd847b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scale\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0"
      ],
      "metadata": {
        "id": "Yxs2vdBSTe7W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Önce fazla boyutları\n",
        "y_train = np.squeeze(y_train)\n",
        "y_test = np.squeeze(y_test)\n",
        "\n",
        "# Sonra tekrar one-hot encoding uygula\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "print(y_train.shape)  # (50000, 10) olmalı\n",
        "print(y_test.shape)   # (10000, 10) olmalı\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPH4oKVJTf60",
        "outputId": "cee99354-ed84-44ba-c7d6-c22e7955f9fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jlujeu3JTgvw",
        "outputId": "248e16d3-80d3-47ef-c327-269d64366d38"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILkT7-CcTisE",
        "outputId": "eba3c794-6aa0-4591-b9b4-68551700079a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "x = Conv2D(16, 3, padding=\"same\", kernel_initializer=\"he_normal\")(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "\n",
        "x = Conv2D(32, 3, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "\n",
        "x = Conv2D(64, 3, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(128, kernel_initializer=\"he_normal\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "\n",
        "outputs = Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "basic_cnn = Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "8IHjWw2wTjmk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizerAdam = Adam(learning_rate= 0.001)\n",
        "\n",
        "#                                           ya da tf.keras.loses.CategoricalCrossentropy\n",
        "#               label verilerimizi categoric hale getirdiğimiz için bu lossu kullanıyoruz\n",
        "#               diğer yolu aşşağıda yorum satırına ekleyeceğim\n",
        "basic_cnn.compile(optimizer= optimizerAdam, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "n7wmUzybTk63"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Farklı yollar\n",
        "\n",
        "# 1 - One Hot yapılmayan veri\n",
        "\n",
        "# Eğer yukarıda verimizi to_categorical yapmasaydık , neden yapmıyoruz diye aklına gelebilir çünkü örneğin elimizde 500 farklı sınıf(class) olan bir veri olduğunu düşünelim one hot hale getirdiğimiz zaman şu şekilde bir yapı oluşur : Örneğin class 5 e ait olsun veri\n",
        "#                               [0,0,0,0,0,1,0,0,0,0,0 ..... ]  450 ye kadar\n",
        "# Bu da verisel olarak sıkıntı yaratacağından bazı durumlarda sparsecategoricalcrosentropy kullanmamız gerekiyor.\n",
        "\n",
        "#  Bu tarz veriler sayısal veriler oluyor örneğin sınıfları 1, 2, 3, 4, 5 diye devam ediyor\n",
        "\n",
        "\n",
        "# Yola gelelim:\n",
        "\n",
        "# y_train = to_categorical(y_train)  # Bu iki satır one hot hale getiren satırlar yapmadığımızı\n",
        "# y_test = to_categorical(y_test)    # varsayalım\n",
        "\n",
        "\n",
        "# Bu durumda\n",
        "# basic_cnn.compile(optimizer= optimizerAdam,\n",
        "#                   loss= \"sparse_categorical_crossentropy\",   # Bu şekilde\n",
        "#                   metrics= [\"accuracy\"])\n",
        "#                                                               ya da\n",
        "# basic_cnn.compile(optimizer=optimizerAdam,\n",
        "#                   loss= tf.keras.losses.SparseCategoricalCrossentropy()) # Şekilinde yazılabilir\n",
        "\n",
        "\n",
        "# 2 - output katmanında Softmax Kullanılmadığında\n",
        "\n",
        "# outputs = Dense(10) # Bu şekilde herhangi bir activation vermeyedebiliriz bu durumda aşşağıdaki şekilde yazarak softmaxı lossumuzun içinde kullanmalıyız\n",
        "\n",
        "# from_logits = True yazarak softmax fonksiyonunun burada uygulanmasını sağlayabiliriz\n",
        "# Bunu neden yapıyoruz tek bir yerde ikisi de hesaplandığından nümerik olarak daha stabil olabiliyormuş\n",
        "\n",
        "# basic_cnn.compile(optimizer=optimizerAdam,\n",
        "#                   loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits= True))"
      ],
      "metadata": {
        "id": "f0Qh7o-tTqH5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(min_delta = 0.01, patience = 10, restore_best_weights = True)"
      ],
      "metadata": {
        "id": "uEr13uPRW3KR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_cnn.fit(x_train, y_train,\n",
        "              epochs = 40,\n",
        "              batch_size = 32, # Default değeri normalde de 32 hiç yazmayabilirdik\n",
        "              validation_data = (x_test, y_test),\n",
        "              callbacks = [early_stopping]) # Yukarıda yazdığımız early_stoppingi buraya callback olarak ekledik\n",
        "                                            # Burada yapacağı şey modelimizdeki defalut olarak \"val_loss\" değeri\n",
        "                                            # min_delta kısmındaki yazdığımız değer kadar iyileşme göstermiyorsa\n",
        "                                            # patience(sabır) değerine verdiğimiz miktar kadar bekler ardından modeli durdurur\n",
        "                                            # restore_best_weights parametresi ise o zamana kadarki en iyi ağırlıkları getirir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1C7bjuETqBJ",
        "outputId": "faf170a4-5805-4481-c777-179dd5874029"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12ms/step - accuracy: 0.4831 - loss: 1.4516 - val_accuracy: 0.6683 - val_loss: 0.9223\n",
            "Epoch 2/40\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 7ms/step - accuracy: 0.7323 - loss: 0.7706 - val_accuracy: 0.6563 - val_loss: 0.9836\n",
            "Epoch 3/40\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8457 - loss: 0.4642 - val_accuracy: 0.6942 - val_loss: 0.8931\n",
            "Epoch 4/40\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9357 - loss: 0.2191 - val_accuracy: 0.6556 - val_loss: 1.2304\n",
            "Epoch 5/40\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9671 - loss: 0.1154 - val_accuracy: 0.6251 - val_loss: 1.6324\n",
            "Epoch 6/40\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9760 - loss: 0.0806 - val_accuracy: 0.6609 - val_loss: 1.5140\n",
            "Epoch 7/40\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.0650 - val_accuracy: 0.6799 - val_loss: 1.4717\n",
            "Epoch 8/40\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9806 - loss: 0.0580 - val_accuracy: 0.6788 - val_loss: 1.5428\n",
            "Epoch 9/40\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9850 - loss: 0.0471 - val_accuracy: 0.6714 - val_loss: 1.6303\n",
            "Epoch 10/40\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9851 - loss: 0.0459 - val_accuracy: 0.6909 - val_loss: 1.6893\n",
            "Epoch 11/40\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0327 - val_accuracy: 0.6863 - val_loss: 1.7001\n",
            "Epoch 12/40\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9857 - loss: 0.0448 - val_accuracy: 0.6955 - val_loss: 1.4653\n",
            "Epoch 13/40\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.9873 - loss: 0.0364 - val_accuracy: 0.6796 - val_loss: 1.5542\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78662d8170d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic CNN modelimizde aldığımız sonuçlar\n",
        "\n",
        "basic_cnn.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PJe92kkYd6P",
        "outputId": "85ca34e6-fc37-45da-94d2-e83d7701b6fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6909 - loss: 0.9006\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8931491374969482, 0.6941999793052673]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notlarım"
      ],
      "metadata": {
        "id": "stAhoNkaVcoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bu veride Kullanılmayacak Olsada Kendi Notlarım Olarak Ayarladığım İçin Functional API Hakkındaki Diğer Şeyler"
      ],
      "metadata": {
        "id": "RB8lD5mJUgW0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Multi-Input , Multi-Output**"
      ],
      "metadata": {
        "id": "UtYfP7q5Vr81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tabiki sadece aşşağıdaki gibi bir model değil farklı farklı bir sürü model oluşturabiliriz functional Api bize farklı farklı bir sürü çeşit\n",
        "# model oluşturma esnekliği sağlıyor bunlar sadece birer örnek\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "# Burada Görüntü ve sayısal olarak iki tane verimiz olacak en sonda bunları tek bir outputta birleştireceğiz\n",
        "\n",
        "\n",
        "def multi_input_model():\n",
        "  image_input = Input(shape=(32, 32, 3), name = \"categorical input\")\n",
        "\n",
        "  x = Conv2D(16,3 , padding= \"same\")(image_input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "\n",
        "  x = Conv2D(32, 3, padding= \"same\")(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "\n",
        "  x = Flatten()(x) # Bunun yerinde ileride GloabalAveragePooling Kullanımı da aynı işlemi farklı bir şekilde yapıyor\n",
        "                   # Flatten bu işlemin sonunda 8, 8, 64) şekline sahip tensörü (8 × 8 × 64) = (4096,) haline getiriyor\n",
        "                   # Dezavantajı Parametre sayısını çok artırabilir. Büyük bir tensörü dümdüz yapınca,\n",
        "                   # çok fazla ağırlık içeren büyük bir tam bağlı katmana ihtiyaç duyar.\n",
        "\n",
        "                   # GlobalAveragePooling çok yüksek miktarda parametre azaltımı yapıyor , overfittingi azaltıyor,\n",
        "                   # Feature Maplerin özelliklerini daha iyi yansıtıyor\n",
        "                   # Dezavantajı Çok fazla bilgi kaybına sebep olabilr\n",
        "                   # Küçük boyutlu feature maplerde anlamlı sonuçlar vermeyebiliyor\n",
        "\n",
        "# Şimdi sayısal veri\n",
        "\n",
        "  num_input = Input(shape=(5,), name = \"numerical_input\")\n",
        "  y = Dense(64, activation=\"relu\")(num_input)\n",
        "  y = Dense(128, activation=\"relu\")(y)\n",
        "\n",
        "\n",
        "  merged = Concatenate()([x, y])\n",
        "\n",
        "\n",
        "  output = Dense(1, activation = \"linear\", name = \"output\")(merged)\n",
        "\n",
        "  mlin_model = Model(inputs = [image_input, num_input], outputs = outputs)\n",
        "\n",
        "  mlin_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
        "                    loss = [\"mse\"],\n",
        "                    metrics = [\"mae\"])\n",
        "\n",
        "  return mlin_model\n",
        "\n",
        "# ------------------------------------------------------------------- #\n",
        "#                   Multi Output Model\n",
        "\n",
        "def multi_output_model():\n",
        "  input1 = Input(shape=(10, ), name = \"input\") # inputumuz burada tek\n",
        "\n",
        "  x = Dense(32, activation = \"relu\")(input1)\n",
        "  x = Dense(64, activation = \"relu\")(x)\n",
        "\n",
        "  regression_output = Dense(1, activation = \"linear\", name = \"regression_output\")(x)\n",
        "\n",
        "\n",
        "  classification_output = Dense(3, activation = \"softmax\", name = \"classification_output\")(x)\n",
        "\n",
        "  mopt_model = Model(inputs = input1, outputs = [regression_output, classification_output])\n",
        "\n",
        "  mopt_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
        "                    loss = {\"regression_output\" : \"mse\",            # İki ayrı çıktımız için iki ayrı kayıp fonksiyonu ve metrics\n",
        "                            \"classification_output\" : \"categorical_crossentropy\"},\n",
        "                    metrics = {\"regression_output\" : \"mae\",\n",
        "                               \"classification_output\" : \"accuracy\"})             # İkisi de tek bir kayıp fonksiyonu ile çalışabilecek olsaydı dahi\n",
        "                                                                                   # İksii içinde ayrı ayrı yazmak syntax açısından da sistem açısından\n",
        "                                                                                   # daha iyi sanırım hem metrics hem loss açısından\n",
        "  return mopt_model\n",
        "\n",
        "# ---------------------------------------------------------------------- #\n",
        "#                 Hem Multi İnput Hem Multi Output\n",
        "\n",
        "\n",
        "# Yukarıkdakilere çizmedim ama bunu anlamak diğer ikisini anlamak gibi bir şey o yüzden ;\n",
        "\n",
        "#\n",
        "# input1(image) --> Conv2D --> MaxPooling2D --> Flatten -->                             --> classification_output()(merged)\n",
        "#                                                             # Merge(Concatanate) -->\n",
        "# input2(numeric) --> Dense(16) --> Dense(32) ------------- >                           --> regression_output()(merged)\n",
        "\n",
        "# Yukarıdaki şema tarzında bir model oluşturacağız buradakinden farklı yapılması gereken işleme , veriye göre farklı farklı birsürü farklı model türü\n",
        "# tabiki olabiliyor bu yukarıdada yazdığım gibi sadece bir örnek\n",
        "\n",
        "\n",
        "\n",
        "def multi_input_multi_output():\n",
        "\n",
        "  image_data = Input(shape=(32, 32, 3))\n",
        "\n",
        "  x = Conv2D(16, 3, padding = \"same\")(image_data)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x = MaxPooling2D()(x)\n",
        "  x = Flatten()(x)\n",
        "\n",
        "\n",
        "  numerical_data = Input(shape=(10, ))\n",
        "  y = Dense(16, activation = \"relu\")(numerical_data)\n",
        "  y = Dense(32, activation = \"relu\")(y)\n",
        "\n",
        "  # Merge işlemi ! Bu kısım Modelden modele ileride TransferLearning kısmında falan da değişiyor add, concatanate, Multiply, Subtract,\n",
        "  # Average, Maximum tarzında farklı merge etme işlemleri de var şuanda concatanate kullanacağım\n",
        "\n",
        "  merged_data = Concatenate()([x, y])\n",
        "\n",
        "\n",
        "  image_output = Dense(3, activation = \"softmax\", name = \"regression_output2\")(merged_data)\n",
        "  numerical_output = Dense(1, activation = \"linear\", name = \"classification_output2\")(merged_data)\n",
        "\n",
        "\n",
        "  mlin_mopt_model = Model(inputs = [image_data, numerical_data], outputs = [image_output, numerical_output])\n",
        "\n",
        "  mlin_mopt_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
        "                          loss = {\"regression_output2\" : \"mse\",\n",
        "                                  \"classification_output2\" : \"categorical_crossentropy\"},\n",
        "                          metrics = {\"regression_output2\" : \"mae\",\n",
        "                                     \"classification_output2\" : \"accuracy\"})\n",
        "  return mlin_mopt_model\n",
        "\n",
        "\n",
        "# Modellerimizin yapılarına bakalım\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Multi İnput Outputun görselleştirilmesi diğerleri de yapılabilir\n",
        "\n",
        "model_3 = multi_input_multi_output()\n",
        "plot_model(model_3, to_file=\"multi_input_multi_output.png\", show_shapes=True, show_layer_names=True, dpi = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "_veNF8AxV0fR",
        "outputId": "a54c4fe2-9d65-4dc4-de4f-efff577c4ed8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {
        "id": "HAMWUufK1v28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Residual Block ve ResNet Mimarisi Tarzı Model"
      ],
      "metadata": {
        "id": "1qr2KxG6wYlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual Block (artık blok), derin sinir ağlarındaki gradyan kaybolma (vanishing gradient) sorununu çözmek için kullanılan bir yapıdır.\n",
        "# ResNet (Residual Network) mimarisiyle popüler olmuştur.\n",
        "# Normal blokta giriş, katmanlardan geçirilir ve doğrudan çıkışa ulaşır.\n",
        "# Residual Block'ta ise giriş verisi bir kopyasıyla doğrudan çıkışa eklenir (skip connection)."
      ],
      "metadata": {
        "id": "z9sG2syxu7rR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual Blocks\n",
        "\n",
        "# Öncelikle Residual(Artık) Bloklarımızı oluşturacağız bunlar aldıkları inputları sona da ekleyecek bu blokları her yerde değil modelimizde\n",
        "# aralara skip connection istediğimiz yerlere serpiştireceğiz\n",
        "\n",
        "# Bu blokları her katmanda değil, model içinde belirli noktalara ekleriz.\n",
        "# Örneğin: CNN mimarisinde her konvolüsyon katmanına residual bağlantı eklemek gereksiz olabilir.\n",
        "# Bunun yerine, belli katmanlardan sonra residual blokları koyarak modelin derinliğini ve öğrenme kapasitesini artırırız."
      ],
      "metadata": {
        "id": "0hSZJA8Fw4Co"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters = 16, kernel_size = (3, 3)):\n",
        "  shortcut = x # Yukarıda yazdığımız x bizim inputumuz oluyor burada onun bir kopyasını shortcut içine attık\n",
        "\n",
        "  x = Conv2D(filters, kernel_size, padding=\"same\")(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "\n",
        "  x = Conv2D(filters, kernel_size, padding = \"same\")(x)\n",
        "  x = BatchNormalization()(x)\n",
        "                                          # Mantık şu iki tane aynı input aslında birisi bazı işlemlerden geçiyor diğeri geçmiyor en son acfunc dan\n",
        "                                          # önce ikisi toplanıyor ve öylece giriyor\n",
        "  x = tf.keras.layers.Add()([shortcut, x]) # Skip Connection !! Burada Önemli olan ReLU Aktivasyon fonksiyonundan önce vermiş olmamız\n",
        "  x = Activation(\"relu\")(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "-oCX1kuhxp-2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet Tarzı Mimari"
      ],
      "metadata": {
        "id": "7TfB-GZJy0gV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_resnet_model(input_shape = (32, 32, 3), num_classes = 10):\n",
        "  inputs = Input(shape=input_shape)\n",
        "\n",
        "  x = Conv2D(32, 3, padding = \"same\", activation = \"relu\")(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D()(x)\n",
        "\n",
        "  # Residual Blocks\n",
        "  # Burada sona (x) yazmadık neden? çünkü zaten input olarak x değerini veriyoruz\n",
        "  x = residual_block(x, 32, kernel_size=3) # kernel_size burada verdim ama yukarıda default olarak 3 * 3 ayarladık zaten\n",
        "  x = residual_block(x, 32)\n",
        "\n",
        "  x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "  x = residual_block(x, 64)\n",
        "  x = residual_block(x, 64)\n",
        "\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D()(x) # Parametremiz çok yüksek olmasın overfit az olsun diye bu sefer tercih sebebi\n",
        "  # Output\n",
        "\n",
        "  outputs = Dense(num_classes)(x) # Aktivasyon Fonksiyonu Kullanmadık Aşşağıdaki Lossa Bak!\n",
        "\n",
        "\n",
        "  resnet_model_1 = Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "  resnet_model_1.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
        "                       loss = tf.keras.losses.CategoricalCrossentropy(from_logits= True), # Burada categorical_crossentropy ile de çalışıyor\n",
        "                       metrics = [\"accuracy\"])\n",
        "\n",
        "  return resnet_model_1"
      ],
      "metadata": {
        "id": "837x14qhy2no"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = create_resnet_model()\n",
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1WTnVTRI1IHz",
        "outputId": "9dcc9100-25c8-4225-adf8-88f87123b316"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m896\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m9,248\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m9,248\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m9,248\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m9,248\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                           │                        │                │ batch_normalization_8… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m18,496\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,928\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_9 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,928\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                           │                        │                │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,928\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m36,928\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m256\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_12             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m650\u001b[0m │ global_average_poolin… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                           │                        │                │ batch_normalization_8… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                           │                        │                │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_12             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ global_average_poolin… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m206,410\u001b[0m (806.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206,410</span> (806.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m205,578\u001b[0m (803.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,578</span> (803.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m832\u001b[0m (3.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> (3.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.fit(x_train, y_train,\n",
        "                 epochs = 10,\n",
        "                 batch_size = 32,\n",
        "                 validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRr1dKdQ1XIU",
        "outputId": "02aa8cd0-5497-4e2d-e3e8-667f2d7e4483"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.4529 - loss: 1.5221 - val_accuracy: 0.5082 - val_loss: 1.6340\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.6705 - loss: 0.9275 - val_accuracy: 0.6585 - val_loss: 0.9693\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7385 - loss: 0.7574 - val_accuracy: 0.6726 - val_loss: 0.9416\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7733 - loss: 0.6472 - val_accuracy: 0.7279 - val_loss: 0.8306\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8060 - loss: 0.5665 - val_accuracy: 0.6856 - val_loss: 0.9574\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8239 - loss: 0.5108 - val_accuracy: 0.7438 - val_loss: 0.7993\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8436 - loss: 0.4508 - val_accuracy: 0.7836 - val_loss: 0.6477\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8609 - loss: 0.4040 - val_accuracy: 0.7852 - val_loss: 0.6264\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8730 - loss: 0.3720 - val_accuracy: 0.7806 - val_loss: 0.6860\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8856 - loss: 0.3300 - val_accuracy: 0.7778 - val_loss: 0.7099\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78662d3f6350>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Yukarıdaki modelimiz oakdar iyi bir sonuç vermedi daha iyi sonuçlar alabilmek için modelimizi daha da derinleştireceğiz aşşağıda\n",
        "resnet_model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "6eUo-w8L1g3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852baba8-a4be-430a-f140-ab3e666d9ef4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7737 - loss: 0.7063\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7099364399909973, 0.7778000235557556]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Daha Derin ResNet Tarzı Model"
      ],
      "metadata": {
        "id": "LH8V3gxVGvUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation"
      ],
      "metadata": {
        "id": "1otNb8zjGzXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aşşağıda modelimizin daha iyi anlaması için sadece katmanları arttıracağız eğer verimiz az olsaydı Data augmentation yapabilirdik\n",
        "# Nasıl Data Augmentation yapabiliriz imagedatagenartor ya da seqeuntial model ile iki tane çeşidini yazayım\n",
        "\n",
        "\n",
        "\n",
        "# Seqeuntial ile data augmentation :\n",
        "\n",
        "\n",
        "\n",
        "# data_augmentation = tf.keras.models.Sequential([\n",
        "#     tf.keras.layers.RandomZoom(0.2), # Rastgele zoomlanmış fotoğraflar oluşturacak\n",
        "#     tf.keras.layers.RandomFlip(\"horizontal\"), # yatay şekilde verileri oynatacak (değiştirilebilir)\n",
        "#     tf.keras.layers.RandomRotation(0.2) # Hareket ettirecek\n",
        "# ])\n",
        "\n",
        "# Yukarıda hazırladık zenginleştirme modelimizi\n",
        "\n",
        "# Şu şekillerde kullanıyoruz\n",
        "# augmented_image = data_augmentation(image, training = False)     # Buradaki training false olmalı test sırasında verimize uygulanmamsı için\n",
        "\n",
        "# Bunu direk modelimizin içinde input aldıktan sonraki kısıma da ekleyebiliriz\n",
        "\n",
        "# inputs = Input(shape=(32, 32, 3))\n",
        "# x = data_augmentation(inputs)\n",
        "\n",
        "\n",
        "\n",
        "# ImageDataGenerator ile Data Augmentation :\n",
        "\n",
        "\n",
        "# Data Augmentation seçenekleri\n",
        "# datagen = ImageDataGenerator(\n",
        "#     rotation_range=20,  # 20 dereceye kadar rastgele döndürme\n",
        "#     width_shift_range=0.2,  # Genişlik kaydırma\n",
        "#     height_shift_range=0.2,  # Yükseklik kaydırma\n",
        "#     shear_range=0.2,  # Kesme dönüşümü\n",
        "#     zoom_range=0.2,  # Zoom\n",
        "#     horizontal_flip=True,  # Yatay çevirme\n",
        "#     fill_mode='nearest'  # Boş kalan pikselleri doldurma yöntemi\n",
        "# )\n",
        "\n",
        "# # Örneğin veriyi NumPy array olarak artırma\n",
        "# augmented_data = datagen.flow(X_train, y_train, batch_size=32)\n",
        "\n",
        "# # Modeli eğitme\n",
        "# model.fit(augmented_data, epochs=10, validation_data=(X_test, y_test))\n",
        "\n"
      ],
      "metadata": {
        "id": "Rm7jSOFKC2SJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_deep_resnet_model(input_shape=(32, 32, 3), num_classes=10):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "\n",
        "    x = residual_block(x, 32)\n",
        "    x = residual_block(x, 32)\n",
        "\n",
        "    x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = residual_block(x, 64)\n",
        "    x = residual_block(x, 64)\n",
        "\n",
        "    x = Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = residual_block(x, 128)\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    x = Conv2D(256, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = residual_block(x, 256)\n",
        "    x = residual_block(x, 256)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation=\"relu\")(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    deep_resnet_model = Model(inputs=inputs, outputs=outputs)\n",
        "    deep_resnet_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                              metrics=[\"accuracy\"])\n",
        "    return deep_resnet_model"
      ],
      "metadata": {
        "id": "8lYqpJNeDD6L"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Daha Derin resnet modelimizi oluşturuyoruz\n",
        "deep_resnet = create_deep_resnet_model()\n",
        "\n",
        "\n",
        "# Learning Rate Schedular\n",
        "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 5, verbose = 1)\n",
        "# Yukarıdaki satırda modelimiz öğrenirken modelimizin daha iyi öğrenmesi için kullandık bu ne yapar val loss belirli bir süre\n",
        "# iyileşmezse learning_rate(öğrenme oranı) nı verdiğimiz (factor) değerine göre düşürür\n",
        "\n",
        "\n",
        "# Fit kısmı\n",
        "deep_resnet.fit(x_train, y_train,\n",
        "                epochs = 25,\n",
        "                batch_size = 32,\n",
        "                validation_data = (x_test, y_test),\n",
        "                callbacks = [lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swe0P3-UDulu",
        "outputId": "aca9812b-388d-4f73-a774-b3eab7b202dd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 28ms/step - accuracy: 0.3569 - loss: 1.7569 - val_accuracy: 0.5366 - val_loss: 1.3035 - learning_rate: 0.0010\n",
            "Epoch 2/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 20ms/step - accuracy: 0.5884 - loss: 1.1705 - val_accuracy: 0.4379 - val_loss: 2.0250 - learning_rate: 0.0010\n",
            "Epoch 3/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.6756 - loss: 0.9442 - val_accuracy: 0.6701 - val_loss: 0.9452 - learning_rate: 0.0010\n",
            "Epoch 4/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.7350 - loss: 0.7865 - val_accuracy: 0.6726 - val_loss: 0.9532 - learning_rate: 0.0010\n",
            "Epoch 5/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.7725 - loss: 0.6763 - val_accuracy: 0.6329 - val_loss: 1.1548 - learning_rate: 0.0010\n",
            "Epoch 6/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8070 - loss: 0.5824 - val_accuracy: 0.6939 - val_loss: 0.9234 - learning_rate: 0.0010\n",
            "Epoch 7/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.8321 - loss: 0.5019 - val_accuracy: 0.7246 - val_loss: 0.8386 - learning_rate: 0.0010\n",
            "Epoch 8/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 19ms/step - accuracy: 0.8491 - loss: 0.4574 - val_accuracy: 0.7815 - val_loss: 0.6469 - learning_rate: 0.0010\n",
            "Epoch 9/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8681 - loss: 0.3954 - val_accuracy: 0.7962 - val_loss: 0.6422 - learning_rate: 0.0010\n",
            "Epoch 10/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.8895 - loss: 0.3330 - val_accuracy: 0.7861 - val_loss: 0.6708 - learning_rate: 0.0010\n",
            "Epoch 11/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.8992 - loss: 0.2952 - val_accuracy: 0.8073 - val_loss: 0.6214 - learning_rate: 0.0010\n",
            "Epoch 12/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.9140 - loss: 0.2575 - val_accuracy: 0.7625 - val_loss: 0.7814 - learning_rate: 0.0010\n",
            "Epoch 13/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.9226 - loss: 0.2264 - val_accuracy: 0.7466 - val_loss: 1.0134 - learning_rate: 0.0010\n",
            "Epoch 14/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.9329 - loss: 0.1978 - val_accuracy: 0.7922 - val_loss: 0.7822 - learning_rate: 0.0010\n",
            "Epoch 15/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.9408 - loss: 0.1759 - val_accuracy: 0.7908 - val_loss: 0.8023 - learning_rate: 0.0010\n",
            "Epoch 16/25\n",
            "\u001b[1m1561/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9483 - loss: 0.1561\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.9483 - loss: 0.1562 - val_accuracy: 0.7960 - val_loss: 0.8410 - learning_rate: 0.0010\n",
            "Epoch 17/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.9703 - loss: 0.0897 - val_accuracy: 0.8189 - val_loss: 0.8603 - learning_rate: 5.0000e-04\n",
            "Epoch 18/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.9821 - loss: 0.0562 - val_accuracy: 0.8262 - val_loss: 0.8319 - learning_rate: 5.0000e-04\n",
            "Epoch 19/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.9831 - loss: 0.0511 - val_accuracy: 0.8172 - val_loss: 0.9344 - learning_rate: 5.0000e-04\n",
            "Epoch 20/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.9849 - loss: 0.0446 - val_accuracy: 0.8251 - val_loss: 0.9117 - learning_rate: 5.0000e-04\n",
            "Epoch 21/25\n",
            "\u001b[1m1561/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9861 - loss: 0.0408\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.9861 - loss: 0.0408 - val_accuracy: 0.8029 - val_loss: 1.0366 - learning_rate: 5.0000e-04\n",
            "Epoch 22/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.9925 - loss: 0.0244 - val_accuracy: 0.8438 - val_loss: 0.9132 - learning_rate: 2.5000e-04\n",
            "Epoch 23/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.9955 - loss: 0.0151 - val_accuracy: 0.8412 - val_loss: 0.9569 - learning_rate: 2.5000e-04\n",
            "Epoch 24/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.9953 - loss: 0.0147 - val_accuracy: 0.8394 - val_loss: 1.0236 - learning_rate: 2.5000e-04\n",
            "Epoch 25/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.9944 - loss: 0.0157 - val_accuracy: 0.8326 - val_loss: 1.0238 - learning_rate: 2.5000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78655901e690>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deep_resnet.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH3-yKRdNBNH",
        "outputId": "c1fb20b5-a26b-4296-b392-ffc498f84906"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8381 - loss: 0.9871\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.02375066280365, 0.8325999975204468]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Subclassing**"
      ],
      "metadata": {
        "id": "ZU60iBauNnIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basit CNN Subclassing"
      ],
      "metadata": {
        "id": "bwjnRiRPNkx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCNN(Model):\n",
        "    def __init__(self, num_classes=10, input_shape=(32, 32, 3)):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.input_shape_ = input_shape  # input_shape saklanıyor\n",
        "\n",
        "        # Conv Katmanları\n",
        "        self.conv1 = Conv2D(16, 3, padding=\"same\")\n",
        "        self.bn1 = BatchNormalization()\n",
        "        self.act1 = Activation(\"relu\")\n",
        "\n",
        "        self.conv2 = Conv2D(32, 3, padding=\"same\")\n",
        "        self.bn2 = BatchNormalization()\n",
        "        self.act2 = Activation(\"relu\")\n",
        "\n",
        "        self.conv3 = Conv2D(64, 3, padding=\"same\")\n",
        "        self.bn3 = BatchNormalization()\n",
        "        self.act3 = Activation(\"relu\")\n",
        "\n",
        "        # Flatten & Dense\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = Dense(128, activation=\"relu\")\n",
        "        self.fc2 = Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = self.act1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "        x = self.act2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x, training=training)\n",
        "        x = self.act3(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        return self.fc2(x)  # Çıktı\n",
        "\n",
        "# Modeli oluştururken input_shape belirtelim\n",
        "sub_class_model = CustomCNN(num_classes=10, input_shape=(32, 32, 3))\n",
        "\n",
        "# Modeli çağırmadan önce input_shape’i belirtmeliyiz!\n",
        "sub_class_model.build(input_shape=(None, 32, 32, 3))\n",
        "\n",
        "# Modelin yapısını yazdır\n",
        "sub_class_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "5bv955ZKNFXT",
        "outputId": "55617dfa-6f9a-4197-bb5e-eba4034477b0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'custom_cnn_7', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"custom_cnn_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"custom_cnn_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_145 (\u001b[38;5;33mConv2D\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_138              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_122 (\u001b[38;5;33mActivation\u001b[0m)          │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_146 (\u001b[38;5;33mConv2D\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_139              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_123 (\u001b[38;5;33mActivation\u001b[0m)          │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_147 (\u001b[38;5;33mConv2D\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_140              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_124 (\u001b[38;5;33mActivation\u001b[0m)          │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_145 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_138              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_146 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_139              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_147 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_140              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)          │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sub_class_model.compile(optimizer = Adam(learning_rate=0.001), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"] )\n",
        "\n",
        "# # Learning Rate Schedular\n",
        "# lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 5, verbose = 1)\n",
        "\n",
        "# # Fit kısmı\n",
        "# sub_class_model.fit(x_train, y_train,\n",
        "#                 epochs = 25,\n",
        "#                 batch_size = 32,\n",
        "#                 validation_data = (x_test, y_test),\n",
        "#                 callbacks = [lr])"
      ],
      "metadata": {
        "id": "fpKGc2EpNkWx"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Residual Block ile Subclassing**"
      ],
      "metadata": {
        "id": "K7KGKZTXRwry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(Model):\n",
        "    def __init__(self, filters):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv2D(filters, 3, padding=\"same\") # Buraların içindeki filtre sayısı filters olmalı\n",
        "        self.bn1 = BatchNormalization()\n",
        "        self.act1 = Activation(\"relu\")\n",
        "\n",
        "        self.conv2 = Conv2D(filters, 3, padding=\"same\")\n",
        "        self.bn2 = BatchNormalization()\n",
        "        self.act2 = Activation(\"relu\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.act1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        # Skip Connection\n",
        "        x = tf.keras.layers.Add()([x, inputs])\n",
        "        return self.act2(x)  #  Çıkışı döndürüyoruz"
      ],
      "metadata": {
        "id": "IWWpNphnNrBY"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualCNN(Model):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv2D(16, 3, padding=\"same\")\n",
        "        self.bn1 = BatchNormalization()\n",
        "        self.act1 = Activation(\"relu\")\n",
        "\n",
        "        self.res_block1 = ResidualBlock(16)  # Residual Block'lar\n",
        "        self.res_block2 = ResidualBlock(16)\n",
        "\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)) # Overfittingi engelleyelim\n",
        "        self.drp = Dropout(0.5)\n",
        "        self.fc2 = Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.act1(x)\n",
        "\n",
        "        x = self.res_block1(x)\n",
        "        x = self.res_block2(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.drp(x)\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "id": "LMbcTezvNq_A"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_model = ResidualCNN()\n",
        "\n",
        "last_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate= 0.00001),\n",
        "                   loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "                   metrics = [\"accuracy\"])\n",
        "\n",
        "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 5, verbose = 1)\n",
        "\n",
        "\n",
        "last_model.fit(x_train, y_train,\n",
        "                epochs = 25,\n",
        "                batch_size = 32,\n",
        "                validation_data = (x_test, y_test),\n",
        "                callbacks = [lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OrAbFgDT7n3",
        "outputId": "03e0fbe8-47ae-4904-c50f-d6663a4d6dec"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.2476 - loss: 3.1740 - val_accuracy: 0.3850 - val_loss: 2.5514 - learning_rate: 1.0000e-05\n",
            "Epoch 2/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3889 - loss: 2.4753 - val_accuracy: 0.4158 - val_loss: 2.2997 - learning_rate: 1.0000e-05\n",
            "Epoch 3/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.4333 - loss: 2.2483 - val_accuracy: 0.4471 - val_loss: 2.1504 - learning_rate: 1.0000e-05\n",
            "Epoch 4/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4535 - loss: 2.1220 - val_accuracy: 0.4567 - val_loss: 2.0591 - learning_rate: 1.0000e-05\n",
            "Epoch 5/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4736 - loss: 2.0265 - val_accuracy: 0.4748 - val_loss: 1.9878 - learning_rate: 1.0000e-05\n",
            "Epoch 6/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4816 - loss: 1.9607 - val_accuracy: 0.4769 - val_loss: 1.9361 - learning_rate: 1.0000e-05\n",
            "Epoch 7/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4950 - loss: 1.8907 - val_accuracy: 0.4884 - val_loss: 1.8741 - learning_rate: 1.0000e-05\n",
            "Epoch 8/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5091 - loss: 1.8407 - val_accuracy: 0.5106 - val_loss: 1.8106 - learning_rate: 1.0000e-05\n",
            "Epoch 9/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5218 - loss: 1.7750 - val_accuracy: 0.5113 - val_loss: 1.7706 - learning_rate: 1.0000e-05\n",
            "Epoch 10/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5262 - loss: 1.7324 - val_accuracy: 0.5212 - val_loss: 1.7254 - learning_rate: 1.0000e-05\n",
            "Epoch 11/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5355 - loss: 1.6931 - val_accuracy: 0.5280 - val_loss: 1.6909 - learning_rate: 1.0000e-05\n",
            "Epoch 12/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5428 - loss: 1.6560 - val_accuracy: 0.5328 - val_loss: 1.6595 - learning_rate: 1.0000e-05\n",
            "Epoch 13/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5454 - loss: 1.6204 - val_accuracy: 0.5367 - val_loss: 1.6233 - learning_rate: 1.0000e-05\n",
            "Epoch 14/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5575 - loss: 1.5857 - val_accuracy: 0.5390 - val_loss: 1.5988 - learning_rate: 1.0000e-05\n",
            "Epoch 15/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.5629 - loss: 1.5547 - val_accuracy: 0.5478 - val_loss: 1.5742 - learning_rate: 1.0000e-05\n",
            "Epoch 16/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5695 - loss: 1.5192 - val_accuracy: 0.5462 - val_loss: 1.5670 - learning_rate: 1.0000e-05\n",
            "Epoch 17/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5731 - loss: 1.5010 - val_accuracy: 0.5502 - val_loss: 1.5359 - learning_rate: 1.0000e-05\n",
            "Epoch 18/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5780 - loss: 1.4776 - val_accuracy: 0.5542 - val_loss: 1.5197 - learning_rate: 1.0000e-05\n",
            "Epoch 19/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5797 - loss: 1.4566 - val_accuracy: 0.5382 - val_loss: 1.5369 - learning_rate: 1.0000e-05\n",
            "Epoch 20/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.5914 - loss: 1.4337 - val_accuracy: 0.5598 - val_loss: 1.4846 - learning_rate: 1.0000e-05\n",
            "Epoch 21/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5923 - loss: 1.4101 - val_accuracy: 0.5656 - val_loss: 1.4674 - learning_rate: 1.0000e-05\n",
            "Epoch 22/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5976 - loss: 1.3931 - val_accuracy: 0.5658 - val_loss: 1.4538 - learning_rate: 1.0000e-05\n",
            "Epoch 23/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6017 - loss: 1.3786 - val_accuracy: 0.5716 - val_loss: 1.4359 - learning_rate: 1.0000e-05\n",
            "Epoch 24/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6073 - loss: 1.3569 - val_accuracy: 0.5714 - val_loss: 1.4337 - learning_rate: 1.0000e-05\n",
            "Epoch 25/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6094 - loss: 1.3408 - val_accuracy: 0.5765 - val_loss: 1.4076 - learning_rate: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x786529754350>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sağlam bir overfitting var ama şuanda yoruldum şimdilik bukadar :d\n",
        "\n",
        "last_model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02b4XxeeVvRh",
        "outputId": "43b9e844-f19e-4d70-e8fe-556615d76b9b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7019 - loss: 1.0650\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0833613872528076, 0.694599986076355]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Muhtemelen Transfer Learning Kullanarak yapmak en iyisi olacak ama henüz daha oraya çalışmadım"
      ],
      "metadata": {
        "id": "rconf41gVyNj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}